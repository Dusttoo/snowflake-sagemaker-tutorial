{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animal Adoption Model Deployment\n",
    "This notebook deploys the trained model to SageMaker for real-time predictions and demonstrates how to make predictions on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Configuration and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded from config.json\n",
      "Using S3 bucket: animal-insights-ae1a1bd9\n",
      "Using AWS region: us-east-1\n",
      "SageMaker role: arn:aws:iam::239285815587:role/sagemaker-execution...\n",
      "SageMaker session initialized in us-east-1 - deployment enabled\n"
     ]
    }
   ],
   "source": [
    "# Configuration and Model Loading\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import boto3\n",
    "try:\n",
    "    import sagemaker\n",
    "except ImportError:\n",
    "    sagemaker = None\n",
    "\n",
    "def load_config():\n",
    "    \"\"\"Load configuration with multiple fallback options\"\"\"\n",
    "    # Option 1: Load from config.json (recommended)\n",
    "    config_file = Path('./config.json')\n",
    "    if config_file.exists():\n",
    "        with open(config_file) as f:\n",
    "            config = json.load(f)\n",
    "        print(f\"Configuration loaded from {config_file}\")\n",
    "        return config\n",
    "    \n",
    "    # Option 2: Try environment variables\n",
    "    if os.environ.get('S3_BUCKET_NAME'):\n",
    "        config = {\n",
    "            's3_bucket_name': os.environ['S3_BUCKET_NAME'],\n",
    "            'aws_region': os.environ.get('AWS_REGION', 'us-east-1'),\n",
    "            'sagemaker_role_arn': os.environ.get('SAGEMAKER_ROLE_ARN', '')\n",
    "        }\n",
    "        print(\"Configuration loaded from environment variables\")\n",
    "        return config\n",
    "    \n",
    "    # Option 3: Interactive input (beginner-friendly fallback)\n",
    "    print(\"Configuration not found. Let's set it up interactively.\")\n",
    "    print(\"(You can skip this by running: python config_generator.py)\")\n",
    "    \n",
    "    config = {}\n",
    "    bucket_name = input(\"Enter your S3 bucket name (from terraform output): \").strip()\n",
    "    config['s3_bucket_name'] = bucket_name\n",
    "    config['aws_region'] = 'us-east-1'\n",
    "    \n",
    "    # For deployment notebook, SageMaker role is more important\n",
    "    sagemaker_role = input(\"Enter SageMaker role ARN (required for deployment): \").strip()\n",
    "    if sagemaker_role:\n",
    "        config['sagemaker_role_arn'] = sagemaker_role\n",
    "    \n",
    "    # Save for next time\n",
    "    with open('./config.json', 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    print(\"Configuration saved to config.json for future use\")\n",
    "    return config\n",
    "\n",
    "# Load configuration\n",
    "try:\n",
    "    config = load_config()\n",
    "    BUCKET_NAME = config['s3_bucket_name']\n",
    "    AWS_REGION = config.get('aws_region', 'us-east-1')\n",
    "    SAGEMAKER_ROLE = config.get('sagemaker_role_arn', None)\n",
    "    \n",
    "    print(f\"Using S3 bucket: {BUCKET_NAME}\")\n",
    "    print(f\"Using AWS region: {AWS_REGION}\")\n",
    "    \n",
    "    if SAGEMAKER_ROLE:\n",
    "        print(f\"SageMaker role: {SAGEMAKER_ROLE[:50]}...\")\n",
    "        if sagemaker is None:\n",
    "            print(\"SageMaker package not available\")\n",
    "            sagemaker_session = None\n",
    "        else:\n",
    "            boto_sess = boto3.Session(region_name=AWS_REGION)\n",
    "            sagemaker_session = sagemaker.Session(boto_session=boto_sess)\n",
    "            print(f\"SageMaker session initialized in {AWS_REGION} - deployment enabled\")\n",
    "    else:\n",
    "        print(\"No SageMaker role configured - local testing only\")\n",
    "        sagemaker_session = None\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Configuration cancelled. Please run this cell again when ready.\")\n",
    "    BUCKET_NAME = None\n",
    "    AWS_REGION = 'us-east-1'\n",
    "    SAGEMAKER_ROLE = None\n",
    "    sagemaker_session = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Load Trained Model and Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model artifacts...\n",
      "‚úÖ Model loaded from ./models/animal_adoption_model.pkl\n",
      "‚úÖ Encoders loaded from ./models/label_encoders.pkl\n",
      "‚úÖ Model info loaded from ./models/model_info.json\n",
      "\n",
      "Model Information:\n",
      "Model type: RandomForestClassifier\n",
      "Features: 6\n",
      "Feature names: ['animal_type', 'sex_outcome', 'age_in_days', 'primary_breed', 'color', 'outcome_month']\n",
      "Target: adopted_label\n",
      "Encoders available: ['animal_type', 'sex_outcome', 'primary_breed', 'color']\n"
     ]
    }
   ],
   "source": [
    "def load_model_artifacts():\n",
    "    \"\"\"Load the trained model, encoders, and metadata\"\"\"\n",
    "    \n",
    "    # Check if model artifacts exist\n",
    "    model_path = './models/animal_adoption_model.pkl'\n",
    "    encoders_path = './models/label_encoders.pkl'\n",
    "    info_path = './models/model_info.json'\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"‚ùå Model file not found: {model_path}\\n\"\n",
    "            \"Please run the ML training notebook (02_ml_training.ipynb) first to train and save the model.\"\n",
    "        )\n",
    "    \n",
    "    # Load model\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"‚úÖ Model loaded from {model_path}\")\n",
    "    \n",
    "    # Load encoders\n",
    "    if os.path.exists(encoders_path):\n",
    "        encoders = joblib.load(encoders_path)\n",
    "        print(f\"‚úÖ Encoders loaded from {encoders_path}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Encoders file not found: {encoders_path}\")\n",
    "        encoders = None\n",
    "    \n",
    "    # Load model info\n",
    "    if os.path.exists(info_path):\n",
    "        with open(info_path, 'r') as f:\n",
    "            model_info = json.load(f)\n",
    "        print(f\"‚úÖ Model info loaded from {info_path}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Model info file not found: {info_path}\")\n",
    "        model_info = None\n",
    "    \n",
    "    return model, encoders, model_info\n",
    "\n",
    "# Load all artifacts\n",
    "print(\"Loading model artifacts...\")\n",
    "model, encoders, model_info = load_model_artifacts()\n",
    "\n",
    "# Display model information\n",
    "print(\"\\nModel Information:\")\n",
    "print(f\"Model type: {type(model).__name__}\")\n",
    "if model_info:\n",
    "    print(f\"Features: {model_info.get('n_features', 'Unknown')}\")\n",
    "    print(f\"Feature names: {model_info.get('feature_names', ['Unknown'])}\")\n",
    "    print(f\"Target: {model_info.get('target_name', 'Unknown')}\")\n",
    "if encoders:\n",
    "    print(f\"Encoders available: {list(encoders.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Create Inference Script for SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Inference script created: ./code/inference.py\n",
      "‚úÖ Model artifacts copied to code directory for deployment\n",
      "‚úÖ Packaged model artifact: ./code/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "def create_inference_script():\n",
    "    \"\"\"Create the inference script for SageMaker deployment\"\"\"\n",
    "    \n",
    "    # Create code directory\n",
    "    os.makedirs('./code', exist_ok=True)\n",
    "    \n",
    "    inference_script = '''\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Load the model and encoders for inference\"\"\"\n",
    "    model = joblib.load(os.path.join(model_dir, 'animal_adoption_model.pkl'))\n",
    "    encoders = joblib.load(os.path.join(model_dir, 'label_encoders.pkl'))\n",
    "    \n",
    "    return {'model': model, 'encoders': encoders}\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    import io, json, numpy as np, pandas as pd\n",
    "\n",
    "    if request_content_type == \"application/json\":\n",
    "        payload = json.loads(request_body)\n",
    "        if isinstance(payload, dict) and \"instances\" in payload:\n",
    "            data = payload[\"instances\"]\n",
    "            df = pd.DataFrame(data)\n",
    "        else:\n",
    "            df = pd.DataFrame(payload)\n",
    "        return df\n",
    "\n",
    "    if request_content_type in (\"text/csv\", \"text/plain\"):\n",
    "        from io import StringIO\n",
    "        return pd.read_csv(StringIO(request_body), header=None)\n",
    "\n",
    "    if request_content_type == \"application/x-npy\":\n",
    "        buf = io.BytesIO(request_body if isinstance(request_body, (bytes, bytearray)) else request_body.encode(\"latin1\"))\n",
    "        arr = np.load(buf, allow_pickle=False)\n",
    "        # if you know the column order from training:\n",
    "        # cols = [\"animal_type\",\"sex_outcome\",\"age_in_days\",\"primary_breed\",\"color\",\"outcome_month\"]\n",
    "        # return pd.DataFrame(arr, columns=cols) if arr.ndim == 2 else pd.DataFrame([arr], columns=cols)\n",
    "        return arr  # if your predict_fn handles numpy too\n",
    "\n",
    "    raise ValueError(f\"Unsupported content type: {request_content_type}\")\n",
    "\n",
    "def predict_fn(input_data, model_dict):\n",
    "    \"\"\"Make predictions on input data\"\"\"\n",
    "    model = model_dict['model']\n",
    "    encoders = model_dict.get('encoders', None)\n",
    "\n",
    "    \n",
    "    # Preprocess the input data\n",
    "    processed_data = input_data.copy()\n",
    "    \n",
    "   \n",
    "    # If encoders are present, apply them; else assume the model can handle raw features (Pipeline)\n",
    "    if encoders:\n",
    "        for column, encoder in encoders.items():\n",
    "            if column in processed_data.columns:\n",
    "                processed_data[column] = processed_data[column].astype(str)\n",
    "                unseen_mask = ~processed_data[column].isin(getattr(encoder, \"classes_\", []))\n",
    "                if unseen_mask.any() and hasattr(encoder, \"classes_\"):\n",
    "                    most_common = encoder.classes_[0]\n",
    "                    processed_data.loc[unseen_mask, column] = most_common\n",
    "                processed_data[column] = encoder.transform(processed_data[column])\n",
    "\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(processed_data)\n",
    "    # Try to compute probabilities; gracefully degrade if unavailable\n",
    "    probs = None\n",
    "    try:\n",
    "        probs = model.predict_proba(processed_data)\n",
    "    except Exception:\n",
    "        try:\n",
    "            scores = model.decision_function(processed_data)\n",
    "            if scores.ndim == 1:\n",
    "                # Convert scores to pseudo-probabilities (sigmoid)\n",
    "                import numpy as np\n",
    "                probs = np.vstack([1/(1+np.exp(scores)), 1/(1+np.exp(-scores))]).T\n",
    "            else:\n",
    "                probs = scores  # best-effort\n",
    "        except Exception:\n",
    "            probs = None\n",
    "\n",
    "    result = {'predictions': predictions.tolist()}\n",
    "    if probs is not None:\n",
    "        result['probabilities'] = probs.tolist()\n",
    "    return result\n",
    "\n",
    "\n",
    "def output_fn(prediction, content_type):\n",
    "    \"\"\"Format the prediction output\"\"\"\n",
    "    if content_type == 'application/json':\n",
    "        return json.dumps(prediction)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {content_type}\")\n",
    "'''\n",
    "    \n",
    "    # Write the inference script\n",
    "    script_path = './code/inference.py'\n",
    "    with open(script_path, 'w') as f:\n",
    "        f.write(inference_script.strip())\n",
    "    \n",
    "    print(f\"‚úÖ Inference script created: {script_path}\")\n",
    "    return script_path\n",
    "\n",
    "# Create the inference script\n",
    "inference_script_path = create_inference_script()\n",
    "\n",
    "# Also copy model artifacts to code directory for SageMaker\n",
    "import shutil\n",
    "try:\n",
    "    shutil.copy('./models/animal_adoption_model.pkl', './code/')\n",
    "    shutil.copy('./models/label_encoders.pkl', './code/')\n",
    "    if os.path.exists('./models/model_info.json'):\n",
    "        shutil.copy('./models/model_info.json', './code/')\n",
    "    print(\"‚úÖ Model artifacts copied to code directory for deployment\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Warning: Could not copy model artifacts: {e}\")\n",
    "    \n",
    "# Package model artifacts for SageMaker (must be a tar.gz with files at root)\n",
    "import tarfile\n",
    "tar_path = './code/model.tar.gz'\n",
    "try:\n",
    "    with tarfile.open(tar_path, 'w:gz') as tar:\n",
    "        tar.add('./code/animal_adoption_model.pkl', arcname='animal_adoption_model.pkl')\n",
    "        # Encoders are optional; include if present\n",
    "        if os.path.exists('./code/label_encoders.pkl'):\n",
    "            tar.add('./code/label_encoders.pkl', arcname='label_encoders.pkl')\n",
    "        if os.path.exists('./code/model_info.json'):\n",
    "            tar.add('./code/model_info.json', arcname='model_info.json')\n",
    "    print(f\"‚úÖ Packaged model artifact: {tar_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to create model tarball: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Local Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model predictions locally...\n",
      "Sample test data:\n",
      "  animal_type    sex_outcome  age_in_days       primary_breed       color  \\\n",
      "0         Dog  Spayed Female          365            Pit Bull       Brown   \n",
      "1         Cat  Neutered Male          730  Domestic Shorthair       Black   \n",
      "2         Dog    Intact Male          180  Labrador Retriever      Yellow   \n",
      "3         Cat  Spayed Female         1095             Siamese  Seal Point   \n",
      "\n",
      "   outcome_month  \n",
      "0              6  \n",
      "1              3  \n",
      "2              9  \n",
      "3             12  \n",
      "‚ö†Ô∏è  Found unseen categories in primary_breed: ['Pit Bull', 'Domestic Shorthair', 'Labrador Retriever']\n",
      "   Replaced with: American\n",
      "‚ö†Ô∏è  Found unseen categories in color: ['Yellow', 'Seal Point']\n",
      "   Replaced with: Black\n",
      "\n",
      "Prediction Results:\n",
      "  Animal 1: Adopted (confidence: 0.678)\n",
      "  Animal 2: Not Adopted (confidence: 0.578)\n",
      "  Animal 3: Not Adopted (confidence: 0.953)\n",
      "  Animal 4: Not Adopted (confidence: 0.640)\n",
      "\n",
      "‚úÖ Local testing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "def test_local_predictions():\n",
    "    \"\"\"Test the model locally before deploying to SageMaker\"\"\"\n",
    "    print(\"Testing model predictions locally...\")\n",
    "    \n",
    "    # Create sample test data\n",
    "    sample_data = pd.DataFrame({\n",
    "        'animal_type': ['Dog', 'Cat', 'Dog', 'Cat'],\n",
    "        'sex_outcome': ['Spayed Female', 'Neutered Male', 'Intact Male', 'Spayed Female'],\n",
    "        'age_in_days': [365, 730, 180, 1095],  # 1 year, 2 years, 6 months, 3 years\n",
    "        'primary_breed': ['Pit Bull', 'Domestic Shorthair', 'Labrador Retriever', 'Siamese'],\n",
    "        'color': ['Brown', 'Black', 'Yellow', 'Seal Point'],\n",
    "        'outcome_month': [6, 3, 9, 12]  # June, March, September, December\n",
    "    })\n",
    "    \n",
    "    print(\"Sample test data:\")\n",
    "    print(sample_data)\n",
    "    \n",
    "    # Preprocess the data using our encoders\n",
    "    if encoders:\n",
    "        processed_sample = sample_data.copy()\n",
    "        \n",
    "        for column, encoder in encoders.items():\n",
    "            if column in processed_sample.columns:\n",
    "                # Handle unseen categories\n",
    "                sample_values = processed_sample[column].astype(str)\n",
    "                unseen_mask = ~sample_values.isin(encoder.classes_)\n",
    "                \n",
    "                if unseen_mask.any():\n",
    "                    print(f\"‚ö†Ô∏è  Found unseen categories in {column}: {sample_values[unseen_mask].tolist()}\")\n",
    "                    # Replace with most common class (first in classes_)\n",
    "                    most_common = encoder.classes_[0]\n",
    "                    sample_values[unseen_mask] = most_common\n",
    "                    print(f\"   Replaced with: {most_common}\")\n",
    "                \n",
    "                processed_sample[column] = encoder.transform(sample_values)\n",
    "        \n",
    "        # Make predictions\n",
    "        try:\n",
    "            predictions = model.predict(processed_sample)\n",
    "            probabilities = model.predict_proba(processed_sample)[:, 1]  # Probability of adoption\n",
    "            \n",
    "            print(\"\\nPrediction Results:\")\n",
    "            for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
    "                outcome = \"Adopted\" if pred == 1 else \"Not Adopted\"\n",
    "                confidence = prob if pred == 1 else (1 - prob)\n",
    "                print(f\"  Animal {i+1}: {outcome} (confidence: {confidence:.3f})\")\n",
    "                \n",
    "            print(\"\\n‚úÖ Local testing completed successfully!\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Local prediction failed: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"‚ùå No encoders available for preprocessing\")\n",
    "        return False\n",
    "\n",
    "# Test the model locally\n",
    "local_test_success = test_local_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Deploy Model to SageMaker (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded model artifact to s3://sagemaker-us-east-1-239285815587/models/model.tar.gz\n",
      "üöÄ Creating new endpoint 'animal-adoption-predictor' on ml.t2.medium...\n",
      "---------------!‚úÖ Created endpoint: animal-adoption-predictor\n",
      "üîó Console: https://us-east-1.console.aws.amazon.com/sagemaker/home?region=us-east-1#/endpoints/animal-adoption-predictor\n",
      "Predictor ready.\n"
     ]
    }
   ],
   "source": [
    "def deploy_to_sagemaker(endpoint_name: str = \"animal-adoption-predictor\",\n",
    "                        instance_type: str = \"ml.t2.medium\",\n",
    "                        timeout_secs: int = 900):\n",
    "    \"\"\"\n",
    "    Create or update a SageMaker endpoint in-place.\n",
    "\n",
    "    - If `endpoint_name` does not exist: creates Model, EndpointConfig, Endpoint.\n",
    "    - If `endpoint_name` exists: creates a new Model + EndpointConfig and UPDATEs the endpoint to use them.\n",
    "    \"\"\"\n",
    "    # --- Preconditions ---\n",
    "    if not SAGEMAKER_ROLE or not BUCKET_NAME:\n",
    "        print(\"‚ö†Ô∏è  SageMaker deployment skipped - no AWS configuration available\")\n",
    "        return None\n",
    "    if not local_test_success:\n",
    "        print(\"‚ùå SageMaker deployment aborted - local testing failed\")\n",
    "        return None\n",
    "    if sagemaker_session is None:\n",
    "        print(\"‚ùå No SageMaker session available\")\n",
    "        return None\n",
    "\n",
    "    import os, time\n",
    "    from datetime import datetime\n",
    "    from botocore.exceptions import ClientError\n",
    "    from sagemaker.sklearn.model import SKLearnModel\n",
    "    from sagemaker.base_predictor import Predictor\n",
    "    from sagemaker.base_serializers import JSONSerializer\n",
    "    from sagemaker.base_deserializers import JSONDeserializer\n",
    "\n",
    "    # --- Ensure artifact exists & upload ---\n",
    "    local_artifact = \"./code/model.tar.gz\"\n",
    "    if not os.path.exists(local_artifact):\n",
    "        raise FileNotFoundError(\"model.tar.gz not found. Re-run the packaging cell to create it.\")\n",
    "\n",
    "    model_data_uri = sagemaker_session.upload_data(path=local_artifact, key_prefix=\"models\")\n",
    "    print(f\"‚úÖ Uploaded model artifact to {model_data_uri}\")\n",
    "\n",
    "    # --- Define the Model object (serving image must match your training major/minor where relevant) ---\n",
    "    ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    model_name = f\"animal-adoption-model-{ts}\"\n",
    "    endpoint_config_name = f\"{endpoint_name}-config-{ts}\"\n",
    "\n",
    "    sklearn_model = SKLearnModel(\n",
    "        model_data=model_data_uri,\n",
    "        role=SAGEMAKER_ROLE,\n",
    "        entry_point=\"inference.py\",\n",
    "        source_dir=\"./code\",\n",
    "        framework_version=\"1.2-1\",   \n",
    "        py_version=\"py3\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        name=model_name\n",
    "    )\n",
    "\n",
    "    sm_client = sagemaker_session.boto_session.client(\"sagemaker\", region_name=AWS_REGION)\n",
    "\n",
    "    # --- Helper: does the endpoint already exist? ---\n",
    "    def _endpoint_exists(name: str) -> bool:\n",
    "        try:\n",
    "            sm_client.describe_endpoint(EndpointName=name)\n",
    "            return True\n",
    "        except sm_client.exceptions.ResourceNotFound:\n",
    "            return False\n",
    "        except ClientError as e:\n",
    "            if \"Could not find endpoint\" in str(e):\n",
    "                return False\n",
    "            raise\n",
    "\n",
    "    # --- Waiter/poller ---\n",
    "    def _wait_for_endpoint(name: str, timeout: int):\n",
    "        start = time.time()\n",
    "        last_log = 0\n",
    "        while True:\n",
    "            resp = sm_client.describe_endpoint(EndpointName=name)\n",
    "            status = resp.get(\"EndpointStatus\")\n",
    "            now = time.time()\n",
    "            if now - last_log >= 15:\n",
    "                print(f\"  ‚è≥ Endpoint status: {status} (elapsed: {int(now-start)}s)\")\n",
    "                last_log = now\n",
    "\n",
    "            if status in (\"InService\", \"Failed\", \"OutOfService\", \"Deleting\"):\n",
    "                return status, resp.get(\"FailureReason\")\n",
    "            if now - start > timeout:\n",
    "                raise TimeoutError(f\"Timed out after {timeout}s. Last status={status}\")\n",
    "            time.sleep(8)\n",
    "\n",
    "    try:\n",
    "        if _endpoint_exists(endpoint_name):\n",
    "            print(f\"üîÅ Endpoint '{endpoint_name}' exists. Updating in-place on {instance_type}...\")\n",
    "            # Register the new Model (no deploy yet)\n",
    "            sklearn_model.create(instance_type=instance_type)\n",
    "            # Create a fresh EndpointConfig pointing to the new model\n",
    "            sm_client.create_endpoint_config(\n",
    "                EndpointConfigName=endpoint_config_name,\n",
    "                ProductionVariants=[{\n",
    "                    \"VariantName\": \"AllTraffic\",\n",
    "                    \"ModelName\": model_name,\n",
    "                    \"InitialInstanceCount\": 1,\n",
    "                    \"InstanceType\": instance_type\n",
    "                }]\n",
    "            )\n",
    "            # Update existing endpoint to use the new config\n",
    "            sm_client.update_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                EndpointConfigName=endpoint_config_name\n",
    "            )\n",
    "            status, reason = _wait_for_endpoint(endpoint_name, timeout_secs)\n",
    "            if status != \"InService\":\n",
    "                raise RuntimeError(f\"Endpoint update failed. Status={status}. Reason={reason}\")\n",
    "            print(f\"‚úÖ Updated endpoint in-place: {endpoint_name}\")\n",
    "\n",
    "            predictor = Predictor(endpoint_name=endpoint_name, sagemaker_session=sagemaker_session)\n",
    "        else:\n",
    "            # -------- CREATE FLOW --------\n",
    "            print(f\"üöÄ Creating new endpoint '{endpoint_name}' on {instance_type}...\")\n",
    "            predictor = sklearn_model.deploy(\n",
    "                initial_instance_count=1,\n",
    "                instance_type=instance_type,\n",
    "                endpoint_name=endpoint_name,\n",
    "                wait=True,               # block until InService\n",
    "                model_name=model_name\n",
    "            )\n",
    "            print(f\"‚úÖ Created endpoint: {endpoint_name}\")\n",
    "\n",
    "        # Set JSON IO\n",
    "        predictor.serializer = JSONSerializer()\n",
    "        predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "        print(\n",
    "            \"üîó Console: \"\n",
    "            f\"https://{sagemaker_session.boto_region_name}.console.aws.amazon.com/sagemaker/home\"\n",
    "            f\"?region={sagemaker_session.boto_region_name}#/endpoints/{endpoint_name}\"\n",
    "        )\n",
    "        return predictor\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"‚ùå SageMaker error: {e}\")\n",
    "        print(\"Tip: ensure the instance type is supported in your region (e.g., 'ml.t2.medium' or 'ml.m5.large').\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Deployment error: {e}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "predictor = deploy_to_sagemaker(endpoint_name=\"animal-adoption-predictor\", instance_type=\"ml.t2.medium\")\n",
    "\n",
    "if predictor:\n",
    "    print(\"Predictor ready.\")\n",
    "else:\n",
    "    print(\"No predictor available for inference testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Test SageMaker Endpoint (if deployed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing SageMaker endpoint...\n",
      "‚úÖ SageMaker endpoint test successful!\n",
      "Results: {'predictions': [1, 0], 'probabilities': [[0.32174619152108713, 0.6782538084789125], [0.5782331020192815, 0.42176689798071854]]}\n",
      "üí° SageMaker endpoint testing is commented out.\n",
      "Uncomment the lines above if you deployed the model to SageMaker.\n"
     ]
    }
   ],
   "source": [
    "def test_sagemaker_endpoint(predictor):\n",
    "    if predictor is None:\n",
    "        print(\"‚ö†Ô∏è  No SageMaker endpoint to test\")\n",
    "        return\n",
    "\n",
    "    print(\"üß™ Testing SageMaker endpoint...\")\n",
    "\n",
    "    test_data = {\n",
    "        \"animal_type\": [\"Dog\", \"Cat\"],\n",
    "        \"sex_outcome\": [\"Spayed Female\", \"Neutered Male\"],\n",
    "        \"age_in_days\": [365, 730],\n",
    "        \"primary_breed\": [\"Pit Bull\", \"Domestic Shorthair\"],\n",
    "        \"color\": [\"Brown\", \"Black\"],\n",
    "        \"outcome_month\": [6, 3],\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        result = predictor.predict(test_data) \n",
    "        print(\"‚úÖ SageMaker endpoint test successful!\")\n",
    "        print(\"Results:\", result)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå SageMaker endpoint test failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test the endpoint if it was deployed\n",
    "if 'predictor' in locals():\n",
    "    test_sagemaker_endpoint(predictor)\n",
    "\n",
    "print(\"üí° SageMaker endpoint testing is commented out.\")\n",
    "print(\"Uncomment the lines above if you deployed the model to SageMaker.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Batch Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading data from: ./data/batch_animal_data.csv\n",
      "‚úÖ Loaded 78 records for prediction\n",
      "\n",
      "üìä Prediction Summary:\n",
      "Predicted adoption rate: 15.4%\n",
      "High confidence predictions (>80%): 26\n",
      "Average confidence: 0.715\n",
      "‚úÖ Results saved to: ./data/predictions.csv\n"
     ]
    }
   ],
   "source": [
    "def make_batch_predictions(\n",
    "    input_file_path,\n",
    "    output_file_path=None,\n",
    "    model_obj=None,\n",
    "    encoders_obj=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Make batch predictions on a CSV file using a fitted model and label encoders.\n",
    "    - Reapplies training-time preprocessing: fillna for numeric, 'unknown' for categoricals, unseen-category handling.\n",
    "    - Uses the same feature column order your model was trained with.\n",
    "    \"\"\"\n",
    "\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # --- Resolve model / encoders from args or known globals ---\n",
    "    model_candidate_order = [model_obj, globals().get(\"loaded_model\"), globals().get(\"model\")]\n",
    "    model_use = next((m for m in model_candidate_order if m is not None), None)\n",
    "\n",
    "    encoders_candidate_order = [encoders_obj, globals().get(\"loaded_encoders\"), globals().get(\"label_encoders\"), globals().get(\"encoders\")]\n",
    "    encoders_use = next((e for e in encoders_candidate_order if e is not None), None)\n",
    "\n",
    "    if model_use is None:\n",
    "        print(\"‚ùå No fitted model found. Pass model_obj=... or ensure 'loaded_model' or 'model' exists.\")\n",
    "        return None\n",
    "    if encoders_use is None:\n",
    "        print(\"‚ùå No label encoders found. Pass encoders_obj=... or ensure 'loaded_encoders' or 'label_encoders' exists.\")\n",
    "        return None\n",
    "\n",
    "    # --- Required columns + training order (must match your training) ---\n",
    "    required_columns = ['animal_type', 'sex_outcome', 'age_in_days', 'primary_breed', 'color', 'outcome_month']\n",
    "    categorical_cols = ['animal_type', 'sex_outcome', 'primary_breed', 'color']\n",
    "    numeric_cols = ['age_in_days', 'outcome_month']\n",
    "\n",
    "    # --- Load input ---\n",
    "    if not os.path.exists(input_file_path):\n",
    "        print(f\"‚ùå Input file not found: {input_file_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"üìÇ Loading data from: {input_file_path}\")\n",
    "    data = pd.read_csv(input_file_path)\n",
    "    print(f\"‚úÖ Loaded {len(data):,} records for prediction\")\n",
    "\n",
    "    # --- Column checks ---\n",
    "    missing = [c for c in required_columns if c not in data.columns]\n",
    "    if missing:\n",
    "        print(f\"‚ùå Missing required columns: {missing}\")\n",
    "        print(f\"Available columns: {list(data.columns)}\")\n",
    "        return None\n",
    "\n",
    "    # --- Copy & minimal preprocessing (align with training pipeline) ---\n",
    "    X = data[required_columns].copy()\n",
    "\n",
    "    # 1) Fill categoricals with 'unknown' and cast to string\n",
    "    for c in categorical_cols:\n",
    "        X[c] = X[c].astype(str).fillna('unknown').replace({'nan': 'unknown', 'None': 'unknown'})\n",
    "\n",
    "    # 2) Numeric fills ‚Äì mirror training behavior\n",
    "    #    age_in_days: median; outcome_month: fallback to 1 if missing/invalid\n",
    "    if X['age_in_days'].isna().any():\n",
    "        age_median = X['age_in_days'].median()\n",
    "        X['age_in_days'] = X['age_in_days'].fillna(age_median)\n",
    "    # If any non-numeric slipped in, coerce and fill again\n",
    "    X['age_in_days'] = pd.to_numeric(X['age_in_days'], errors='coerce')\n",
    "    if X['age_in_days'].isna().any():\n",
    "        X['age_in_days'] = X['age_in_days'].fillna(X['age_in_days'].median())\n",
    "\n",
    "    X['outcome_month'] = pd.to_numeric(X['outcome_month'], errors='coerce')\n",
    "    if X['outcome_month'].isna().any():\n",
    "        X['outcome_month'] = X['outcome_month'].fillna(1)\n",
    "    # (Optional) clamp to 1..12 if that‚Äôs your expectation\n",
    "    X['outcome_month'] = X['outcome_month'].clip(lower=1, upper=12)\n",
    "\n",
    "    # 3) Label-encode categoricals using training encoders\n",
    "    for col in categorical_cols:\n",
    "        if col not in encoders_use:\n",
    "            return print(f\"‚ùå Missing encoder for column '{col}'. Keys available: {list(encoders_use.keys())}\") or None\n",
    "\n",
    "        enc = encoders_use[col]\n",
    "        vals = X[col].astype(str)\n",
    "\n",
    "        # Map unseen categories to 'unknown' if present, else to the most frequent training class\n",
    "        unseen_mask = ~vals.isin(enc.classes_)\n",
    "        if unseen_mask.any():\n",
    "            if 'unknown' in enc.classes_:\n",
    "                vals.loc[unseen_mask] = 'unknown'\n",
    "            else:\n",
    "                # Fall back: map to the first class (encoders were fit on training distribution)\n",
    "                vals.loc[unseen_mask] = enc.classes_[0]\n",
    "\n",
    "        # Ensure encoder knows about any injected 'unknown'\n",
    "        if 'unknown' in vals.values and 'unknown' not in enc.classes_:\n",
    "            enc.classes_ = np.append(enc.classes_, 'unknown')\n",
    "\n",
    "        X[col] = enc.transform(vals)\n",
    "\n",
    "    # 4) Ensure column order matches training order\n",
    "    X = X[required_columns]\n",
    "\n",
    "    # 5) Final NaN guard (should be clean already)\n",
    "    if X.isna().any().any():\n",
    "        # As a last resort, fill remaining NaNs: numeric -> median; categorical -> mode(0)\n",
    "        for c in X.columns:\n",
    "            if c in numeric_cols:\n",
    "                X[c] = X[c].fillna(X[c].median())\n",
    "            else:\n",
    "                X[c] = X[c].fillna(X[c].mode().iloc[0])\n",
    "\n",
    "    # --- Predict ---\n",
    "    try:\n",
    "        preds = model_use.predict(X)\n",
    "        probs = model_use.predict_proba(X)[:, 1]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Prediction failed: {e}\")\n",
    "        return None\n",
    "\n",
    "    # --- Assemble results ---\n",
    "    result = data.copy()\n",
    "    result['adoption_prediction'] = preds\n",
    "    result['adoption_probability'] = probs\n",
    "    result['prediction_confidence'] = np.where(preds == 1, probs, 1 - probs)\n",
    "\n",
    "    # --- Summary ---\n",
    "    adoption_rate = (preds == 1).mean() * 100.0\n",
    "    print(\"\\nüìä Prediction Summary:\")\n",
    "    print(f\"Predicted adoption rate: {adoption_rate:.1f}%\")\n",
    "    print(f\"High confidence predictions (>80%): {(result['prediction_confidence'] > 0.8).sum():,}\")\n",
    "    print(f\"Average confidence: {result['prediction_confidence'].mean():.3f}\")\n",
    "\n",
    "    # --- Save (optional) ---\n",
    "    if output_file_path:\n",
    "        result.to_csv(output_file_path, index=False)\n",
    "        print(f\"‚úÖ Results saved to: {output_file_path}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Example usage (uncomment and edit your paths):\n",
    "results = make_batch_predictions(\n",
    "    \"./data/batch_animal_data.csv\",\n",
    "    \"./data/predictions.csv\",\n",
    "    model_obj=model,          \n",
    "    encoders_obj=encoders     \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Cleanup and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Resource Cleanup Instructions\n",
      "==================================================\n",
      "\n",
      "‚ö†Ô∏è  IMPORTANT: Clean up SageMaker resources to avoid charges!\n",
      "\n",
      "If you deployed a SageMaker endpoint:\n",
      "\n",
      "1. Delete the endpoint:\n",
      "   # Uncomment and run this if you deployed an endpoint:\n",
      "   # predictor.delete_endpoint()\n",
      "\n",
      "2. Check AWS Console:\n",
      "   - Go to SageMaker console ‚Üí Endpoints\n",
      "   - Verify no endpoints are running\n",
      "\n",
      "3. Clean up S3 model artifacts:\n",
      "   - Check S3 bucket for uploaded models\n",
      "   - Delete if no longer needed\n",
      "\n",
      "üí° Next Steps for Production:\n",
      "------------------------------\n",
      "1. **Monitoring**: Set up CloudWatch alarms for endpoint health\n",
      "2. **Scaling**: Configure auto-scaling for production traffic\n",
      "3. **Security**: Implement VPC endpoints for private access\n",
      "4. **Model Updates**: Set up automated retraining pipeline\n",
      "5. **A/B Testing**: Deploy multiple model versions for comparison\n",
      "\n",
      "üéØ Integration Options:\n",
      "-------------------------\n",
      "1. **Web App**: Build a simple web interface for predictions\n",
      "2. **API**: Create REST API endpoints using AWS API Gateway\n",
      "3. **Batch Processing**: Schedule daily/weekly batch predictions\n",
      "4. **Real-time Stream**: Process incoming animal data streams\n",
      "\n",
      "============================================================\n",
      "üéâ MODEL DEPLOYMENT NOTEBOOK COMPLETE!\n",
      "============================================================\n",
      "\n",
      "‚úÖ What you accomplished:\n",
      "  ‚Ä¢ Loaded and tested trained model locally\n",
      "  ‚Ä¢ Created SageMaker inference script\n",
      "  ‚Ä¢ Set up deployment pipeline (ready to use)\n",
      "  ‚Ä¢ Created batch prediction functionality\n",
      "\n",
      "üöÄ Your model is ready for production deployment!\n"
     ]
    }
   ],
   "source": [
    "def cleanup_resources():\n",
    "    \"\"\"Instructions for cleaning up SageMaker resources\"\"\"\n",
    "    \n",
    "    print(\"üßπ Resource Cleanup Instructions\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è  IMPORTANT: Clean up SageMaker resources to avoid charges!\")\n",
    "    print(\"\\nIf you deployed a SageMaker endpoint:\")\n",
    "    print(\"\\n1. Delete the endpoint:\")\n",
    "    print(\"   # Uncomment and run this if you deployed an endpoint:\")\n",
    "    print(\"   # predictor.delete_endpoint()\")\n",
    "    print(\"\\n2. Check AWS Console:\")\n",
    "    print(\"   - Go to SageMaker console ‚Üí Endpoints\")\n",
    "    print(\"   - Verify no endpoints are running\")\n",
    "    print(\"\\n3. Clean up S3 model artifacts:\")\n",
    "    print(\"   - Check S3 bucket for uploaded models\")\n",
    "    print(\"   - Delete if no longer needed\")\n",
    "    \n",
    "    print(\"\\nüí° Next Steps for Production:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"1. **Monitoring**: Set up CloudWatch alarms for endpoint health\")\n",
    "    print(\"2. **Scaling**: Configure auto-scaling for production traffic\")\n",
    "    print(\"3. **Security**: Implement VPC endpoints for private access\")\n",
    "    print(\"4. **Model Updates**: Set up automated retraining pipeline\")\n",
    "    print(\"5. **A/B Testing**: Deploy multiple model versions for comparison\")\n",
    "    \n",
    "    print(\"\\nüéØ Integration Options:\")\n",
    "    print(\"-\" * 25)\n",
    "    print(\"1. **Web App**: Build a simple web interface for predictions\")\n",
    "    print(\"2. **API**: Create REST API endpoints using AWS API Gateway\")\n",
    "    print(\"3. **Batch Processing**: Schedule daily/weekly batch predictions\")\n",
    "    print(\"4. **Real-time Stream**: Process incoming animal data streams\")\n",
    "    \n",
    "cleanup_resources()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ MODEL DEPLOYMENT NOTEBOOK COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚úÖ What you accomplished:\")\n",
    "print(\"  ‚Ä¢ Loaded and tested trained model locally\")\n",
    "print(\"  ‚Ä¢ Created SageMaker inference script\")\n",
    "print(\"  ‚Ä¢ Set up deployment pipeline (ready to use)\")\n",
    "print(\"  ‚Ä¢ Created batch prediction functionality\")\n",
    "print(\"\\nüöÄ Your model is ready for production deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
