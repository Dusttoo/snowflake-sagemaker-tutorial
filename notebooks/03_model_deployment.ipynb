{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animal Adoption Model Deployment\n",
    "This notebook deploys the trained model to SageMaker for real-time predictions and demonstrates how to make predictions on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker.predictor import Predictor\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Configuration and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Model Loading\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def load_config():\n",
    "    \"\"\"Load configuration with multiple fallback options\"\"\"\n",
    "    \n",
    "    # Option 1: Load from config.json (recommended)\n",
    "    config_file = Path('../config.json')\n",
    "    if config_file.exists():\n",
    "        with open(config_file) as f:\n",
    "            config = json.load(f)\n",
    "        print(f\"Configuration loaded from {config_file}\")\n",
    "        return config\n",
    "    \n",
    "    # Option 2: Try environment variables\n",
    "    if os.environ.get('S3_BUCKET_NAME'):\n",
    "        config = {\n",
    "            's3_bucket_name': os.environ['S3_BUCKET_NAME'],\n",
    "            'aws_region': os.environ.get('AWS_REGION', 'us-east-1'),\n",
    "            'sagemaker_role_arn': os.environ.get('SAGEMAKER_ROLE_ARN', '')\n",
    "        }\n",
    "        print(\"Configuration loaded from environment variables\")\n",
    "        return config\n",
    "    \n",
    "    # Option 3: Interactive input (beginner-friendly fallback)\n",
    "    print(\"Configuration not found. Let's set it up interactively.\")\n",
    "    print(\"(You can skip this by running: python config_generator.py)\")\n",
    "    \n",
    "    config = {}\n",
    "    bucket_name = input(\"Enter your S3 bucket name (from terraform output): \").strip()\n",
    "    config['s3_bucket_name'] = bucket_name\n",
    "    config['aws_region'] = 'us-east-1'\n",
    "    \n",
    "    # For deployment notebook, SageMaker role is more important\n",
    "    sagemaker_role = input(\"Enter SageMaker role ARN (required for deployment): \").strip()\n",
    "    if sagemaker_role:\n",
    "        config['sagemaker_role_arn'] = sagemaker_role\n",
    "    \n",
    "    # Save for next time\n",
    "    with open('../config.json', 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    print(\"Configuration saved to config.json for future use\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Load configuration\n",
    "try:\n",
    "    config = load_config()\n",
    "    BUCKET_NAME = config['s3_bucket_name']\n",
    "    AWS_REGION = config.get('aws_region', 'us-east-1')\n",
    "    SAGEMAKER_ROLE = config.get('sagemaker_role_arn', None)\n",
    "    \n",
    "    print(f\"Using S3 bucket: {BUCKET_NAME}\")\n",
    "    print(f\"Using AWS region: {AWS_REGION}\")\n",
    "    \n",
    "    if SAGEMAKER_ROLE:\n",
    "        print(f\"SageMaker role: {SAGEMAKER_ROLE[:50]}...\")\n",
    "        \n",
    "        # Initialize SageMaker session\n",
    "        try:\n",
    "            sagemaker_session = sagemaker.Session()\n",
    "            print(\"SageMaker session initialized - deployment enabled\")\n",
    "        except ImportError:\n",
    "            print(\"SageMaker package not available\")\n",
    "            sagemaker_session = None\n",
    "    else:\n",
    "        print(\"No SageMaker role configured - local testing only\")\n",
    "        sagemaker_session = None\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Configuration cancelled. Please run this cell again when ready.\")\n",
    "    BUCKET_NAME = None\n",
    "    AWS_REGION = 'us-east-1'\n",
    "    SAGEMAKER_ROLE = None\n",
    "    sagemaker_session = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Load Trained Model and Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_artifacts():\n",
    "    \"\"\"Load the trained model, encoders, and metadata\"\"\"\n",
    "    \n",
    "    # Check if model artifacts exist\n",
    "    model_path = './models/animal_adoption_model.pkl'\n",
    "    encoders_path = './models/label_encoders.pkl'\n",
    "    info_path = './models/model_info.json'\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"‚ùå Model file not found: {model_path}\\n\"\n",
    "            \"Please run the ML training notebook (02_ml_training.ipynb) first to train and save the model.\"\n",
    "        )\n",
    "    \n",
    "    # Load model\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"‚úÖ Model loaded from {model_path}\")\n",
    "    \n",
    "    # Load encoders\n",
    "    if os.path.exists(encoders_path):\n",
    "        encoders = joblib.load(encoders_path)\n",
    "        print(f\"‚úÖ Encoders loaded from {encoders_path}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Encoders file not found: {encoders_path}\")\n",
    "        encoders = None\n",
    "    \n",
    "    # Load model info\n",
    "    if os.path.exists(info_path):\n",
    "        with open(info_path, 'r') as f:\n",
    "            model_info = json.load(f)\n",
    "        print(f\"‚úÖ Model info loaded from {info_path}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Model info file not found: {info_path}\")\n",
    "        model_info = None\n",
    "    \n",
    "    return model, encoders, model_info\n",
    "\n",
    "# Load all artifacts\n",
    "print(\"Loading model artifacts...\")\n",
    "model, encoders, model_info = load_model_artifacts()\n",
    "\n",
    "# Display model information\n",
    "print(\"\\nModel Information:\")\n",
    "print(f\"Model type: {type(model).__name__}\")\n",
    "if model_info:\n",
    "    print(f\"Features: {model_info.get('n_features', 'Unknown')}\")\n",
    "    print(f\"Feature names: {model_info.get('feature_names', ['Unknown'])}\")\n",
    "    print(f\"Target: {model_info.get('target_name', 'Unknown')}\")\n",
    "if encoders:\n",
    "    print(f\"Encoders available: {list(encoders.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Create Inference Script for SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inference_script():\n",
    "    \"\"\"Create the inference script for SageMaker deployment\"\"\"\n",
    "    \n",
    "    # Create code directory\n",
    "    os.makedirs('../code', exist_ok=True)\n",
    "    \n",
    "    inference_script = '''\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Load the model and encoders for inference\"\"\"\n",
    "    model = joblib.load(os.path.join(model_dir, 'animal_adoption_model.pkl'))\n",
    "    encoders = joblib.load(os.path.join(model_dir, 'label_encoders.pkl'))\n",
    "    \n",
    "    return {'model': model, 'encoders': encoders}\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"Parse input data for prediction\"\"\"\n",
    "    if request_content_type == 'application/json':\n",
    "        input_data = json.loads(request_body)\n",
    "        return pd.DataFrame(input_data)\n",
    "    elif request_content_type == 'text/csv':\n",
    "        return pd.read_csv(StringIO(request_body))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {request_content_type}\")\n",
    "\n",
    "def predict_fn(input_data, model_dict):\n",
    "    \"\"\"Make predictions on input data\"\"\"\n",
    "    model = model_dict['model']\n",
    "    encoders = model_dict['encoders']\n",
    "    \n",
    "    # Preprocess the input data\n",
    "    processed_data = input_data.copy()\n",
    "    \n",
    "    # Apply encoders to categorical columns\n",
    "    for column, encoder in encoders.items():\n",
    "        if column in processed_data.columns:\n",
    "            # Handle unseen categories\n",
    "            processed_data[column] = processed_data[column].astype(str)\n",
    "            unseen_mask = ~processed_data[column].isin(encoder.classes_)\n",
    "            \n",
    "            if unseen_mask.any():\n",
    "                # Replace unseen values with most common class\n",
    "                most_common = encoder.classes_[0]  # First class is often most common\n",
    "                processed_data.loc[unseen_mask, column] = most_common\n",
    "            \n",
    "            processed_data[column] = encoder.transform(processed_data[column])\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(processed_data)\n",
    "    probabilities = model.predict_proba(processed_data)\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions.tolist(),\n",
    "        'probabilities': probabilities.tolist()\n",
    "    }\n",
    "\n",
    "def output_fn(prediction, content_type):\n",
    "    \"\"\"Format the prediction output\"\"\"\n",
    "    if content_type == 'application/json':\n",
    "        return json.dumps(prediction)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {content_type}\")\n",
    "'''\n",
    "    \n",
    "    # Write the inference script\n",
    "    script_path = '../code/inference.py'\n",
    "    with open(script_path, 'w') as f:\n",
    "        f.write(inference_script.strip())\n",
    "    \n",
    "    print(f\"‚úÖ Inference script created: {script_path}\")\n",
    "    return script_path\n",
    "\n",
    "# Create the inference script\n",
    "inference_script_path = create_inference_script()\n",
    "\n",
    "# Also copy model artifacts to code directory for SageMaker\n",
    "import shutil\n",
    "try:\n",
    "    shutil.copy('../models/animal_adoption_model.pkl', '../code/')\n",
    "    shutil.copy('../models/label_encoders.pkl', '../code/')\n",
    "    if os.path.exists('../models/model_info.json'):\n",
    "        shutil.copy('../models/model_info.json', '../code/')\n",
    "    print(\"‚úÖ Model artifacts copied to code directory for deployment\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Warning: Could not copy model artifacts: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Local Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_local_predictions():\n",
    "    \"\"\"Test the model locally before deploying to SageMaker\"\"\"\n",
    "    print(\"Testing model predictions locally...\")\n",
    "    \n",
    "    # Create sample test data\n",
    "    sample_data = pd.DataFrame({\n",
    "        'animal_type': ['Dog', 'Cat', 'Dog', 'Cat'],\n",
    "        'sex_outcome': ['Spayed Female', 'Neutered Male', 'Intact Male', 'Spayed Female'],\n",
    "        'age_in_days': [365, 730, 180, 1095],  # 1 year, 2 years, 6 months, 3 years\n",
    "        'primary_breed': ['Pit Bull', 'Domestic Shorthair', 'Labrador Retriever', 'Siamese'],\n",
    "        'color': ['Brown', 'Black', 'Yellow', 'Seal Point'],\n",
    "        'outcome_month': [6, 3, 9, 12]  # June, March, September, December\n",
    "    })\n",
    "    \n",
    "    print(\"Sample test data:\")\n",
    "    print(sample_data)\n",
    "    \n",
    "    # Preprocess the data using our encoders\n",
    "    if encoders:\n",
    "        processed_sample = sample_data.copy()\n",
    "        \n",
    "        for column, encoder in encoders.items():\n",
    "            if column in processed_sample.columns:\n",
    "                # Handle unseen categories\n",
    "                sample_values = processed_sample[column].astype(str)\n",
    "                unseen_mask = ~sample_values.isin(encoder.classes_)\n",
    "                \n",
    "                if unseen_mask.any():\n",
    "                    print(f\"‚ö†Ô∏è  Found unseen categories in {column}: {sample_values[unseen_mask].tolist()}\")\n",
    "                    # Replace with most common class (first in classes_)\n",
    "                    most_common = encoder.classes_[0]\n",
    "                    sample_values[unseen_mask] = most_common\n",
    "                    print(f\"   Replaced with: {most_common}\")\n",
    "                \n",
    "                processed_sample[column] = encoder.transform(sample_values)\n",
    "        \n",
    "        # Make predictions\n",
    "        try:\n",
    "            predictions = model.predict(processed_sample)\n",
    "            probabilities = model.predict_proba(processed_sample)[:, 1]  # Probability of adoption\n",
    "            \n",
    "            print(\"\\nPrediction Results:\")\n",
    "            for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
    "                outcome = \"Adopted\" if pred == 1 else \"Not Adopted\"\n",
    "                confidence = prob if pred == 1 else (1 - prob)\n",
    "                print(f\"  Animal {i+1}: {outcome} (confidence: {confidence:.3f})\")\n",
    "                \n",
    "            print(\"\\n‚úÖ Local testing completed successfully!\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Local prediction failed: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"‚ùå No encoders available for preprocessing\")\n",
    "        return False\n",
    "\n",
    "# Test the model locally\n",
    "local_test_success = test_local_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Deploy Model to SageMaker (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_to_sagemaker():\n",
    "    \"\"\"Deploy the model to SageMaker endpoint\"\"\"\n",
    "    \n",
    "    if not SAGEMAKER_ROLE or not BUCKET_NAME:\n",
    "        print(\"‚ö†Ô∏è  SageMaker deployment skipped - no AWS configuration available\")\n",
    "        print(\"To deploy to SageMaker:\")\n",
    "        print(\"1. Run terraform apply to create AWS resources\")\n",
    "        print(\"2. Restart this notebook to pick up the configuration\")\n",
    "        return None\n",
    "    \n",
    "    if not local_test_success:\n",
    "        print(\"‚ùå SageMaker deployment aborted - local testing failed\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Deploying model to SageMaker...\")\n",
    "    \n",
    "    try:\n",
    "        # Create SKLearn model\n",
    "        sklearn_model = SKLearnModel(\n",
    "            model_data=f's3://{BUCKET_NAME}/models/',  # Will be created when we upload\n",
    "            role=SAGEMAKER_ROLE,\n",
    "            entry_point='inference.py',\n",
    "            source_dir='../code',\n",
    "            framework_version='1.0-1',\n",
    "            py_version='py3',\n",
    "            sagemaker_session=sagemaker_session\n",
    "        )\n",
    "        \n",
    "        # Deploy the model\n",
    "        endpoint_name = f'animal-adoption-predictor-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "        \n",
    "        print(f\"Creating endpoint: {endpoint_name}\")\n",
    "        print(\"This may take 5-10 minutes...\")\n",
    "        \n",
    "        predictor = sklearn_model.deploy(\n",
    "            initial_instance_count=1,\n",
    "            instance_type='ml.t2.medium',  # Cost-effective for testing\n",
    "            endpoint_name=endpoint_name\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Model deployed successfully!\")\n",
    "        print(f\"Endpoint name: {endpoint_name}\")\n",
    "        print(f\"Endpoint URL: https://{sagemaker_session.boto_region_name}.console.aws.amazon.com/sagemaker/home?region={sagemaker_session.boto_region_name}#/endpoints/{endpoint_name}\")\n",
    "        \n",
    "        return predictor\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå SageMaker deployment failed: {e}\")\n",
    "        print(\"This is often due to:\")\n",
    "        print(\"- Insufficient IAM permissions\")\n",
    "        print(\"- Incorrect S3 bucket configuration\")\n",
    "        print(\"- SageMaker service limits\")\n",
    "        return None\n",
    "\n",
    "# Deploy to SageMaker\n",
    "print(\"üí° SageMaker deployment is commented out to prevent accidental resource creation.\")\n",
    "print(\"Uncomment the line below to deploy to SageMaker:\")\n",
    "print(\"# predictor = deploy_to_sagemaker()\")\n",
    "\n",
    "predictor = deploy_to_sagemaker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Test SageMaker Endpoint (if deployed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sagemaker_endpoint(predictor):\n",
    "    \"\"\"Test the deployed SageMaker endpoint\"\"\"\n",
    "    \n",
    "    if predictor is None:\n",
    "        print(\"‚ö†Ô∏è  No SageMaker endpoint to test (deployment was skipped or failed)\")\n",
    "        return\n",
    "    \n",
    "    print(\"üß™ Testing SageMaker endpoint...\")\n",
    "    \n",
    "    # Test data\n",
    "    test_data = {\n",
    "        'animal_type': ['Dog', 'Cat'],\n",
    "        'sex_outcome': ['Spayed Female', 'Neutered Male'],\n",
    "        'age_in_days': [365, 730],\n",
    "        'primary_breed': ['Pit Bull', 'Domestic Shorthair'],\n",
    "        'color': ['Brown', 'Black'],\n",
    "        'outcome_month': [6, 3]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Make prediction via SageMaker endpoint\n",
    "        result = predictor.predict(test_data)\n",
    "        \n",
    "        print(\"‚úÖ SageMaker endpoint test successful!\")\n",
    "        print(\"Results:\", result)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå SageMaker endpoint test failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test the endpoint if it was deployed\n",
    "if 'predictor' in locals():\n",
    "    test_sagemaker_endpoint(predictor)\n",
    "\n",
    "print(\"üí° SageMaker endpoint testing is commented out.\")\n",
    "print(\"Uncomment the lines above if you deployed the model to SageMaker.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Batch Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch_predictions(input_file_path, output_file_path=None):\n",
    "    \"\"\"Make batch predictions on a CSV file\"\"\"\n",
    "    \n",
    "    if not os.path.exists(input_file_path):\n",
    "        print(f\"‚ùå Input file not found: {input_file_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üìÇ Loading data from: {input_file_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Load the data\n",
    "        data = pd.read_csv(input_file_path)\n",
    "        print(f\"‚úÖ Loaded {len(data):,} records for prediction\")\n",
    "        \n",
    "        # Ensure required columns exist\n",
    "        required_columns = ['animal_type', 'sex_outcome', 'age_in_days', 'primary_breed', 'color', 'outcome_month']\n",
    "        missing_columns = [col for col in required_columns if col not in data.columns]\n",
    "        \n",
    "        if missing_columns:\n",
    "            print(f\"‚ùå Missing required columns: {missing_columns}\")\n",
    "            print(f\"Available columns: {list(data.columns)}\")\n",
    "            return None\n",
    "        \n",
    "        # Preprocess the data\n",
    "        processed_data = data[required_columns].copy()\n",
    "        \n",
    "        if encoders:\n",
    "            for column, encoder in encoders.items():\n",
    "                if column in processed_data.columns:\n",
    "                    # Handle unseen categories\n",
    "                    sample_values = processed_data[column].astype(str)\n",
    "                    unseen_mask = ~sample_values.isin(encoder.classes_)\n",
    "                    \n",
    "                    if unseen_mask.any():\n",
    "                        most_common = encoder.classes_[0]\n",
    "                        sample_values[unseen_mask] = most_common\n",
    "                    \n",
    "                    processed_data[column] = encoder.transform(sample_values)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = model.predict(processed_data)\n",
    "        probabilities = model.predict_proba(processed_data)[:, 1]\n",
    "        \n",
    "        # Add predictions to original data\n",
    "        result_data = data.copy()\n",
    "        result_data['adoption_prediction'] = predictions\n",
    "        result_data['adoption_probability'] = probabilities\n",
    "        result_data['prediction_confidence'] = np.where(\n",
    "            predictions == 1, probabilities, 1 - probabilities\n",
    "        )\n",
    "        \n",
    "        # Summary statistics\n",
    "        adoption_rate = (predictions == 1).mean() * 100\n",
    "        print(f\"\\nüìä Prediction Summary:\")\n",
    "        print(f\"Predicted adoption rate: {adoption_rate:.1f}%\")\n",
    "        print(f\"High confidence predictions (>80%): {(result_data['prediction_confidence'] > 0.8).sum():,}\")\n",
    "        print(f\"Average confidence: {result_data['prediction_confidence'].mean():.3f}\")\n",
    "        \n",
    "        # Save results if output path provided\n",
    "        if output_file_path:\n",
    "            result_data.to_csv(output_file_path, index=False)\n",
    "            print(f\"‚úÖ Results saved to: {output_file_path}\")\n",
    "        \n",
    "        return result_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Batch prediction failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage (commented out - uncomment to use with your data)\n",
    "print(\"Batch prediction example:\")\n",
    "print(\"# results = make_batch_predictions('../data/new_animals.csv', '../data/predictions.csv')\")\n",
    "print(\"\\nTo use batch predictions:\")\n",
    "print(\"1. Prepare a CSV file with the required columns\")\n",
    "print(\"2. Call make_batch_predictions(input_file, output_file)\")\n",
    "print(\"3. Review the predictions in the output file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Cleanup and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_resources():\n",
    "    \"\"\"Instructions for cleaning up SageMaker resources\"\"\"\n",
    "    \n",
    "    print(\"üßπ Resource Cleanup Instructions\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è  IMPORTANT: Clean up SageMaker resources to avoid charges!\")\n",
    "    print(\"\\nIf you deployed a SageMaker endpoint:\")\n",
    "    print(\"\\n1. Delete the endpoint:\")\n",
    "    print(\"   # Uncomment and run this if you deployed an endpoint:\")\n",
    "    print(\"   # predictor.delete_endpoint()\")\n",
    "    print(\"\\n2. Check AWS Console:\")\n",
    "    print(\"   - Go to SageMaker console ‚Üí Endpoints\")\n",
    "    print(\"   - Verify no endpoints are running\")\n",
    "    print(\"\\n3. Clean up S3 model artifacts:\")\n",
    "    print(\"   - Check S3 bucket for uploaded models\")\n",
    "    print(\"   - Delete if no longer needed\")\n",
    "    \n",
    "    print(\"\\nüí° Next Steps for Production:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"1. **Monitoring**: Set up CloudWatch alarms for endpoint health\")\n",
    "    print(\"2. **Scaling**: Configure auto-scaling for production traffic\")\n",
    "    print(\"3. **Security**: Implement VPC endpoints for private access\")\n",
    "    print(\"4. **Model Updates**: Set up automated retraining pipeline\")\n",
    "    print(\"5. **A/B Testing**: Deploy multiple model versions for comparison\")\n",
    "    \n",
    "    print(\"\\nüéØ Integration Options:\")\n",
    "    print(\"-\" * 25)\n",
    "    print(\"1. **Web App**: Build a simple web interface for predictions\")\n",
    "    print(\"2. **API**: Create REST API endpoints using AWS API Gateway\")\n",
    "    print(\"3. **Batch Processing**: Schedule daily/weekly batch predictions\")\n",
    "    print(\"4. **Real-time Stream**: Process incoming animal data streams\")\n",
    "    \n",
    "cleanup_resources()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ MODEL DEPLOYMENT NOTEBOOK COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚úÖ What you accomplished:\")\n",
    "print(\"  ‚Ä¢ Loaded and tested trained model locally\")\n",
    "print(\"  ‚Ä¢ Created SageMaker inference script\")\n",
    "print(\"  ‚Ä¢ Set up deployment pipeline (ready to use)\")\n",
    "print(\"  ‚Ä¢ Created batch prediction functionality\")\n",
    "print(\"\\nüöÄ Your model is ready for production deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
